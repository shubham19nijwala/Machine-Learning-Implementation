{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d53f2a",
   "metadata": {},
   "source": [
    "## COMMON TERMS\n",
    "1. CORPUS (C): Combination of all the words in whole dataset(contains repeated words).\n",
    "2. VOCABULARY (V): Unique words in the corpus.\n",
    "3. DOCUMENT (D): For say we have imdb review dataset, then each individual review is called Document.\n",
    "4. WORD (W): word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b388cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa9ac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch Joker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joker watch Joker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people pass comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joker pass comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text  output\n",
       "0   people watch Joker       1\n",
       "1    Joker watch Joker       1\n",
       "2  people pass comment       0\n",
       "3   Joker pass comment       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'text':['people watch Joker','Joker watch Joker','people pass comment','Joker pass comment'],'output':[1,1,0,0]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058526c",
   "metadata": {},
   "source": [
    "## 1.Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f1400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3070343",
   "metadata": {},
   "source": [
    "### Important Hyperparameters(Default)\n",
    "1. lowercase=True\n",
    "2. tokenizer = None\n",
    "3. stop_word = None\n",
    "4. binary = False   (for sentiment analysis: binary =True)\n",
    "5. max_features = None (setting up this hyperparameter let say, to 5 extract top 5 most frequent words)\n",
    "6. ngram_range=(1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db0b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7ee177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 3, 'watch': 4, 'joker': 1, 'pass': 2, 'comment': 0}\n"
     ]
    }
   ],
   "source": [
    "# vocab\n",
    "\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b731b352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f816dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1],\n",
       "       [0, 2, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [1, 1, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8761cd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(['Joker watch and pass comment']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6f8424",
   "metadata": {},
   "source": [
    "### Disadvantage:\n",
    "e.g:\n",
    "1. This is a very good movie.\n",
    "2. This is not a very good movie.\n",
    "\n",
    "according to Bag of words logic this two vectors are very close which means that the meaning of the two is very close.\n",
    "\n",
    "But this is not the case.\n",
    "\n",
    "Due to small changes when the variation in sentence become too large Bag of words unable to capture it.\n",
    "\n",
    "#### It can be Handled very efficiently by: n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300be22b",
   "metadata": {},
   "source": [
    "### Bag of n-grams\n",
    "\n",
    "#### Bi-grams:(2-words at a time)\n",
    "\n",
    "vocabulary:\n",
    "people watch | watch joker | Joker watch | people pass | pass comment | Joker pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebbb323",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1=CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ec203d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= cv1.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68f8649b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch': 4, 'watch joker': 5, 'joker watch': 1, 'people pass': 3, 'pass comment': 2, 'joker pass': 0}\n"
     ]
    }
   ],
   "source": [
    "# vocab\n",
    "\n",
    "print(cv1.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7e9ab2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 1],\n",
       "       [0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5e0f4d",
   "metadata": {},
   "source": [
    "#### Uni/Bi-grams:(1 or 2 words at a time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e02caaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2=CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce3067c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= cv2.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3d10971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 6, 'watch': 9, 'joker': 1, 'people watch': 8, 'watch joker': 10, 'joker watch': 3, 'pass': 4, 'comment': 0, 'people pass': 7, 'pass comment': 5, 'joker pass': 2}\n"
     ]
    }
   ],
   "source": [
    "# vocab\n",
    "\n",
    "print(cv2.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d3f68c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
       "       [0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f991d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comment' 'joker' 'joker pass' 'joker watch' 'pass' 'pass comment'\n",
      " 'people' 'people pass' 'people watch' 'watch' 'watch joker']\n"
     ]
    }
   ],
   "source": [
    "print(cv2.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c529c05",
   "metadata": {},
   "source": [
    "## 2.Tf-Idf\n",
    "(assigning weightage to words in each document in a way that giving more weight to word which is more frequent in a document but rare in corpus)\n",
    "\n",
    "TF- Term Frequency: probability of term appearing in document (0<TF<1)\n",
    "\n",
    "IDF- Inverse Document Frequency:  rare term in corpus :: IDF increases whereas, frequent term in corpus :: IDF decreases\n",
    "\n",
    "TF = (Number of times term appears in a document) / (Total number of terms in the document)\n",
    "\n",
    "IDF = log((Total number of documents) / (Number of documents containing the term))\n",
    "\n",
    "## TF * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4bcea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "x=tfidf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2b1920e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.49681612, 0.        , 0.61366674, 0.61366674],\n",
       "       [0.        , 0.8508161 , 0.        , 0.        , 0.52546357],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.57735027, 0.        ],\n",
       "       [0.61366674, 0.49681612, 0.61366674, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94cf5854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.51082562 1.22314355 1.51082562 1.51082562 1.51082562]\n",
      "['comment' 'joker' 'pass' 'people' 'watch']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_)\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63427b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
